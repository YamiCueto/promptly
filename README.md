# Promptly ğŸ¤–

[![Deploy Status](https://github.com/YamiCueto/promptly/workflows/Deploy%20to%20GitHub%20Pages/badge.svg)](https://github.com/YamiCueto/promptly/actions)
[![CI Status](https://github.com/YamiCueto/promptly/workflows/CI/badge.svg)](https://github.com/YamiCueto/promptly/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-1.1.0-blue.svg)](https://github.com/YamiCueto/promptly/releases)

Una interfaz de chat moderna y elegante que se conecta tanto a **Ollama local** como a **APIs externas** de proveedores de IA como OpenAI, Anthropic y Groq.

## âœ¨ CaracterÃ­sticas

- ğŸ  **ConexiÃ³n a Ollama Local** - Ejecuta modelos de IA localmente con detecciÃ³n automÃ¡tica
- ğŸ”„ **Auto-detecciÃ³n de Modelos** - Carga automÃ¡ticamente todos tus modelos de Ollama instalados
- ğŸ“œ **Auto-Scroll Inteligente** - Scroll automÃ¡tico suave durante las respuestas de IA
- â˜ï¸ **APIs Externas** - Soporte para OpenAI, Anthropic (Claude), y Groq
- ğŸ¨ **Interfaz Moderna** - DiseÃ±o inspirado en ChatGPT/Claude con Material Design
- ğŸŒ™ **Sistema de Temas** - Tema claro por defecto con opciÃ³n de tema oscuro
- ğŸ“± **Responsive** - Funciona perfectamente en dispositivos mÃ³viles
- ğŸš€ **FÃ¡cil Deploy** - Compatible con GitHub Pages
- âš¡ **Vanilla JavaScript** - Sin frameworks pesados, carga rÃ¡pida
- ğŸ’¾ **Historial Local** - Guarda tus conversaciones en el navegador
-  **Notificaciones Elegantes** - SweetAlert2 para mejor UX
- ğŸ“¤ **Exportar Conversaciones** - Descarga en formato texto o Markdown
- ğŸ¯ **Material Icons** - Iconos consistentes y modernos
- âŒ¨ï¸ **Atajos de Teclado** - NavegaciÃ³n rÃ¡pida y eficiente

## ğŸš€ Demo en Vivo

Visita: [https://yamicueto.github.io/promptly](https://yamicueto.github.io/promptly)

> **ğŸ“‹ IMPORTANTE**: Para configuraciÃ³n completa, troubleshooting y convenciones de desarrollo, consulta [INSTRUCTIONS.md](INSTRUCTIONS.md)

## ğŸ› ï¸ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: Uso Directo (Recomendado)

1. Clona el repositorio:
```bash
git clone https://github.com/YamiCueto/promptly.git
cd promptly
```

2. Abre `index.html` en tu navegador o usa un servidor local:
```bash
# Con Python
python -m http.server 8000

# Con Node.js (si tienes http-server instalado)
npx http-server

# Con VS Code Live Server
# Instala la extensiÃ³n Live Server y haz clic derecho en index.html
```

### OpciÃ³n 2: Deploy en GitHub Pages

1. Fork este repositorio
2. Ve a Settings > Pages
3. Selecciona "Deploy from a branch" 
4. Elige la rama `main` y carpeta `/ (root)`
5. Tu sitio estarÃ¡ disponible en `https://tuusuario.github.io/promptly`

## âš™ï¸ ConfiguraciÃ³n

### Ollama Local

1. **Instala Ollama** en tu sistema:
   - **Windows/macOS/Linux**: Descarga desde [ollama.ai](https://ollama.ai)

2. **Descarga un modelo**:
```bash
ollama pull llama3.2
# o cualquier otro modelo que prefieras
```

3. **Inicia Ollama**:
```bash
ollama serve
```

4. En Promptly:
   - Selecciona "Ollama (Local)" como proveedor
   - Verifica que la URL sea `http://localhost:11434`
   - Haz clic en "Actualizar Modelos" para cargar los modelos disponibles
   - Selecciona tu modelo preferido

### APIs Externas

#### OpenAI
1. ObtÃ©n tu API key desde [platform.openai.com](https://platform.openai.com)
2. En Promptly, selecciona "OpenAI" como proveedor
3. Ingresa tu API key
4. Selecciona el modelo (gpt-4, gpt-3.5-turbo, etc.)

#### Anthropic (Claude)
1. ObtÃ©n tu API key desde [console.anthropic.com](https://console.anthropic.com)
2. Selecciona "Anthropic (Claude)" como proveedor
3. Ingresa tu API key
4. Selecciona el modelo (claude-3-opus, claude-3-sonnet, etc.)

#### Groq
1. ObtÃ©n tu API key desde [console.groq.com](https://console.groq.com)
2. Selecciona "Groq" como proveedor
3. Ingresa tu API key
4. Selecciona el modelo (llama3-70b-8192, mixtral-8x7b-32768, etc.)

## ğŸ¯ CaracterÃ­sticas Destacadas

### ğŸ”„ Auto-detecciÃ³n de Modelos Ollama
- **Carga automÃ¡tica** de todos los modelos instalados en tu Ollama local
- **DetecciÃ³n en tiempo real** - no necesitas configurar manualmente la lista
- **Soporte completo** para cualquier modelo: `llama3.2`, `gpt-oss`, `qwen2.5-coder`, etc.
- **ActualizaciÃ³n dinÃ¡mica** - los modelos aparecen automÃ¡ticamente al instalarlos

### ğŸ“œ Auto-Scroll Inteligente
- **Scroll automÃ¡tico suave** durante las respuestas de la IA
- **Seguimiento en tiempo real** del progreso de la respuesta
- **Scroll continuo** cada 100ms mientras la IA estÃ¡ escribiendo
- **DetenciÃ³n automÃ¡tica** cuando termina la respuesta
- **Optimizado para mÃ³viles** y desktop

### ğŸ¨ Sistema de Temas Mejorado
- **Tema claro por defecto** para mejor legibilidad
- **Alternancia suave** entre tema claro y oscuro
- **Persistencia** - recuerda tu preferencia de tema
- **Material Design** con iconos consistentes
- **Variables CSS** para fÃ¡cil personalizaciÃ³n

### ğŸš€ Rendimiento Optimizado
- **Vanilla JavaScript** - sin dependencias pesadas
- **Carga rÃ¡pida** - menos de 1 segundo de tiempo inicial
- **Material Icons** desde CDN optimizado
- **SweetAlert2** para notificaciones elegantes

## ğŸ”§ CaracterÃ­sticas TÃ©cnicas

### Estructura del Proyecto
```
promptly/
â”œâ”€â”€ index.html          # PÃ¡gina principal
â”œâ”€â”€ css/
â”‚   â””â”€â”€ styles.css      # Estilos principales
â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ config.js       # ConfiguraciÃ³n y utilidades
â”‚   â”œâ”€â”€ providers.js    # Manejo de proveedores de IA
â”‚   â”œâ”€â”€ chat.js         # LÃ³gica del chat
â”‚   â””â”€â”€ app.js          # AplicaciÃ³n principal
â””â”€â”€ README.md
```

### TecnologÃ­as Utilizadas
- **HTML5** - Estructura semÃ¡ntica
- **CSS3** - DiseÃ±o moderno con variables CSS y Flexbox
- **Vanilla JavaScript** - Sin dependencias externas
- **LocalStorage** - Persistencia de configuraciÃ³n y chat
- **Fetch API** - ComunicaciÃ³n con APIs

### CaracterÃ­sticas de Seguridad
- Las API keys se almacenan localmente en tu navegador
- No se envÃ­an datos a terceros (excepto a los proveedores de IA que configures)
- ComunicaciÃ³n HTTPS con todos los proveedores externos

## ğŸ“± Uso

1. **Configura tu proveedor**: Haz clic en el botÃ³n "âš™ï¸ ConfiguraciÃ³n"
2. **Selecciona el proveedor** que prefieras (Ollama local o API externa)
3. **Los modelos se cargan automÃ¡ticamente** - para Ollama, verÃ¡s todos tus modelos instalados
4. **Selecciona tu modelo** desde el selector en el header (actualizado en tiempo real)
5. **Configura los parÃ¡metros** (temperatura, tokens mÃ¡ximos)
6. **Â¡Comienza a chatear!** Escribe tu mensaje y presiona Enter
7. **Disfruta del auto-scroll** - el chat se desplaza automÃ¡ticamente mientras la IA responde

### ğŸ¯ Funcionalidades Especiales

- **Cambio rÃ¡pido de modelo**: Usa el selector del header para cambiar modelos sin abrir configuraciÃ³n
- **Auto-scroll inteligente**: El chat se mantiene automÃ¡ticamente en la Ãºltima respuesta
- **Tema personalizable**: Alternar entre tema claro y oscuro con un clic
- **ExportaciÃ³n flexible**: Descarga conversaciones en formato texto o Markdown
- **Notificaciones elegantes**: Feedback visual para todas las acciones

### Atajos de Teclado
- `Ctrl/Cmd + ,` - Abrir configuraciÃ³n
- `Ctrl/Cmd + K` - Limpiar chat
- `Enter` - Enviar mensaje
- `Shift + Enter` - Nueva lÃ­nea
- `Esc` - Cerrar configuraciÃ³n

## ğŸ¤ Contribuir

Â¡Las contribuciones son bienvenidas! 

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### Ideas para Contribuir
- ğŸ¨ Temas adicionales (coloridos, personalizados)
- ğŸ”Š SÃ­ntesis de voz para las respuestas
- ğŸ“‚ OrganizaciÃ³n de chats en carpetas
- ğŸ” BÃºsqueda en el historial
- ğŸŒ MÃ¡s proveedores de IA (Cohere, Together AI)
- ğŸ“ Plantillas de prompts predefinidos
- âš¡ Streaming en tiempo real para APIs externas
- ğŸ”— Compartir conversaciones pÃºblicamente
- ğŸ“Š EstadÃ­sticas de uso y mÃ©tricas
- ğŸ”Œ Sistema de plugins extensible

### âœ… Ya Implementado
- âœ… **Auto-scroll inteligente** durante respuestas
- âœ… **Auto-detecciÃ³n de modelos Ollama** 
- âœ… **Sistema de temas** claro/oscuro
- âœ… **Exportar conversaciones** en texto y Markdown
- âœ… **Notificaciones elegantes** con SweetAlert2
- âœ… **Material Design** con iconos consistentes
- âœ… **Interfaz responsive** optimizada para mÃ³viles

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ve el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- [Ollama](https://ollama.ai) por hacer la IA local tan accesible
- [OpenAI](https://openai.com) por sus potentes APIs
- [Anthropic](https://anthropic.com) por Claude
- [Groq](https://groq.com) por su inferencia ultra-rÃ¡pida
- La comunidad de desarrolladores por la inspiraciÃ³n constante

## ğŸ“ Soporte

Si tienes problemas o preguntas:

1. Revisa las [Issues](https://github.com/YamiCueto/promptly/issues) existentes
2. Crea una nueva Issue si no encuentras soluciÃ³n
3. Para problemas de Ollama, consulta su [documentaciÃ³n oficial](https://github.com/jmorganca/ollama)

---

**Â¿Te gusta Promptly?** â­ Â¡Dale una estrella al repositorio!

Hecho con â¤ï¸ por [YamiCueto](https://github.com/YamiCueto)